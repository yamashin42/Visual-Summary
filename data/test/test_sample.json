{"abstract": "The exponential growth of scientific literature yields the need for supporting users in effectively and efficiently analyzing and understanding the body of research works. This procedure can be facilitated by providing graphical abstracts -- a visual summary of a scientific publication. Accordingly, previous work presented an initial study on automatically identifying a central figure from a scientific paper that can serve as a visual summary. However, these efforts are currently limited to the biomedical domain only. This is primarily due to the current state-of-the-art relying on supervised machine learning, which requires large amounts of labeled data, and the only existing annotated data set consisting of biomedical research papers only. To alleviate the issues, we build a novel benchmark data set for visual summary identification from scientific publications, which consists of papers presented at conferences of several domains in computer science. We couple this contribution with a new self-supervised learning approach to learn a heuristic matching of inline reference to figures with figure captions, which only requires a collection of scientific papers, thereby reducing the need for large annotated data sets. We evaluate the proposed approach on both the existing biomedical and our newly presented computer science data set. The experimental results suggest that the proposed method is able to outperform the previous state-of-the-art without any annotated training data.",
"figures":[{"number":1, "caption":"Illustration of our proposed self-supervised learning for central figure identification. (a) Existingsupervised learning approach (Yang et al., 2019) requires labeled data for model training. (b) Our proposedself-supervised learning utilizes an inline reference to figure, which can be obtained without manual effort."},
           {"number":2, "caption":"Our model for abstract-caption pair scoring. Paragraphs explicitly mentioning figures are pairedwith the figure captions during training."},
           {"number":3, "caption":"Creation of paragraph-figure pairs used as training instances for our models. For a single traininginstance, positive and negative pairs are created. A figure is paired with paragraphs which refers to thefigure and different one in positive and negative pairs, respectively."},
           {"number":4, "caption":"Histogram of figure numbers annotated as top-3 figure in our proposed CS data set."},
           {"number":5, "caption":"Examples of attention patterns in SciBERT model for (a) higher-ranked sample and (b) lower-ranked sample."}]}