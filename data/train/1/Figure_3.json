{"caption": "Figure 3: Examples of attentions from SciBERT which attends to semantically similar tokens (training and test data are from the CS domain).",
    "mention":"To understand the model behavior, we analyze the attention in SciBERT. We visualize the attention in the Transformer model. We find that most attention maps are consistent with typical classes reported in [32], such as vertical or diagonal attention patterns. In some attention heads, the model attends to the lexical overlap between abstract and caption. The examples of attention matrices produced by heads attending over the same or semantically similar tokens, are shown in Figure 3. In this example, instances of tokens like ’tracking’ and ’when’ appearing in both in abstract and caption have mutually high attention weights. Additionally, pairs of tokens with similar meaning like ’restore’ and ’recovering’ also receive high mutual attention weights."}